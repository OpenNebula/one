#!/bin/bash

# -------------------------------------------------------------------------- #
# Copyright 2002-2018, OpenNebula Project, OpenNebula Systems                #
#                                                                            #
# Licensed under the Apache License, Version 2.0 (the "License"); you may    #
# not use this file except in compliance with the License. You may obtain    #
# a copy of the License at                                                   #
#                                                                            #
# http://www.apache.org/licenses/LICENSE-2.0                                 #
#                                                                            #
# Unless required by applicable law or agreed to in writing, software        #
# distributed under the License is distributed on an "AS IS" BASIS,          #
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   #
# See the License for the specific language governing permissions and        #
# limitations under the License.                                             #
#--------------------------------------------------------------------------- #

# mvds host:remote_system_ds/disk.i fe:SOURCE snapid vmid dsid
#   - fe is the front-end hostname
#   - SOURCE is the path of the disk image in the form DS_BASE_PATH/disk
#   - host is the target host to deploy the VM
#   - remote_system_ds is the path for the system datastore in the host
#   - vmid is the id of the VM
#   - dsid is the target datastore (0 is the system datastore)
#   - snapid is the snapshot id. "-1" for none

SRC=$1
DST=$2
SNAP_ID=$3
VMID=$4
DSID=$5

if [ -z "${ONE_LOCATION}" ]; then
    TMCOMMON=/var/lib/one/remotes/tm/tm_common.sh
else
    TMCOMMON=$ONE_LOCATION/var/remotes/tm/tm_common.sh
fi

DRIVER_PATH=$(dirname $0)

. $TMCOMMON

#-------------------------------------------------------------------------------
# Get Image information
#-------------------------------------------------------------------------------

DISK_ID=$(basename ${SRC} | cut -d. -f2)

XPATH="${DRIVER_PATH}/../../datastore/xpath.rb --stdin"

unset i j XPATH_ELEMENTS

while IFS= read -r -d '' element; do
    XPATH_ELEMENTS[i++]="$element"
done < <(onevm show -x $VMID| $XPATH \
                    /VM/TEMPLATE/DISK[DISK_ID=$DISK_ID]/SOURCE \
                    /VM/TEMPLATE/DISK[DISK_ID=$DISK_ID]/CLONE)

DISK_SRC="${XPATH_ELEMENTS[j++]}"
CLONE="${XPATH_ELEMENTS[j++]}"

#-------------------------------------------------------------------------------
# Set dst path and dir
#-------------------------------------------------------------------------------
SRC_PATH=`arg_path $SRC`
SRC_HOST=`arg_host $SRC`
SRC_DIR=`dirname $SRC_PATH`

DST_ARG_PATH=`arg_path $DST`

SRC_DS_PATH="$(dirname $(dirname $(dirname $SRC_PATH)))"
DST_DS_PATH="$(dirname $(dirname $DST_ARG_PATH))"

DST_PATH="${SRC_DS_PATH}${DST_ARG_PATH##$DST_DS_PATH}"

if [ "$SNAP_ID" != "-1" ]; then
    [ "$CLONE" != "YES" ] && SRC_PATH="$DISK_SRC"
    SRC_PATH="$SRC_PATH.snap/$SNAP_ID"
fi

#-------------------------------------------------------------------------------
# Move the image back to the datastore
#-------------------------------------------------------------------------------

CPDS_CMD=$(cat <<EOF
SRC_READLN=\$($READLINK -f $SRC_PATH)
DST_READLN=\$($READLINK -f $DST_PATH)

if [ \( -L $SRC_PATH \) -a \( "\$SRC_READLN" = "\$DST_READLN" \) ] ; then
    echo "Not moving files to image repo, they are the same"
else
    $QEMU_IMG convert $SRC_PATH -O qcow2 $DST_PATH
fi
EOF
)

# TODO: after taking a snapshot, if you try to save the current state, and if
# cache='none', it will fail, as the changes are not commited to the image. This
# happens even after running 'sync' inside the guest and in the hypervisor. A
# solution that does work is to run:
#
#     $ touch $DST_PATH
#     $ virsh blockcopy --domain $DEPLOY_ID $TARGET $DST_PATH --wait --verbose
#
# However this is in turn problematic because there is no easy way to tell if the
# global configuration for taking snapshot is live, detach or suspend. If it's
# live, and the VM is running, the virsh blockcopy can be run, otherwise it should
# never be run. If we can detect this configuration parameter in this script, and
# check with libvirt if the vm is running, we should have all the information we
# need to do choose whether to run the blockcopy or not.

log "Copying $SRC_PATH to datastore as $DST_PATH"

ssh_exec_and_log $SRC_HOST "$CPDS_CMD" "Could not move image $DST_PATH"

exit 0
